{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c7ef26",
   "metadata": {},
   "source": [
    "## LSTM Modeling from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e62bbd",
   "metadata": {},
   "source": [
    "### Import Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89be0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from random import shuffle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ef050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('C:/Users/aksha/Downloads/7610 Final/train.csv')\n",
    "print (train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5070a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:/Users/aksha/Downloads/7610 Final/test.csv')\n",
    "print (test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2acd0",
   "metadata": {},
   "source": [
    "### Preprocessing, Stemming and Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff369ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.drop(['id', 'qid1', 'qid2'], 1)\n",
    "test1 = test.drop(['test_id'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f792d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.fillna('')\n",
    "test1 = test1.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c03251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb37242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n",
    "    # Clean the text, with the option to remove stop_words and to stem words.\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"What's\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "    text = re.sub(r\"china\", \"China\", text)\n",
    "    text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\"quora\", \"Quora\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"gps\", \"GPS\", text)\n",
    "    text = re.sub(r\"gst\", \"GST\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"the US\", \"America\", text)\n",
    "    text = re.sub(r\"Astrology\", \"astrology\", text)\n",
    "    text = re.sub(r\"Method\", \"method\", text)\n",
    "    text = re.sub(r\"Find\", \"find\", text) \n",
    "    text = re.sub(r\"banglore\", \"Banglore\", text)\n",
    "    text = re.sub(r\" J K \", \" JK \", text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        text = text.split()\n",
    "        text = [w for w in text if not w in stop_words]\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ad5622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1['question1_modified'] = train1.apply(lambda x: text_to_wordlist(x['question1']), axis = 1)\n",
    "train1['question2_modified'] = train1.apply(lambda x: text_to_wordlist(x['question2']), axis = 1)\n",
    "test1['question1_modified'] = test1.apply(lambda x: text_to_wordlist(x['question1']), axis = 1)\n",
    "test1['question2_modified'] = test1.apply(lambda x: text_to_wordlist(x['question2']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20c228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(train1['question1_modified'], open('pickle_train_question1_modified', 'wb'))\n",
    "pickle.dump(train1['question2_modified'], open('pickle_train_question2_modified', 'wb'))\n",
    "\n",
    "pickle.dump(test1['question1_modified'], open('pickle_test_question1_modified', 'wb'))\n",
    "pickle.dump(test1['question2_modified'], open('pickle_test_question2_modified', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b34d66",
   "metadata": {},
   "source": [
    "### Tokenization of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4bb6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "train1_text = np.hstack([train1.question1_modified, train1.question2_modified])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train1_text)\n",
    "train1['tokenizer_1'] = tokenizer.texts_to_sequences(train1.question1_modified)\n",
    "train1['tokenizer_2'] = tokenizer.texts_to_sequences(train1.question2_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf99e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_text = np.hstack([test1.question1_modified, test1.question2_modified])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test1_text)\n",
    "test1['tokenizer_1'] = tokenizer.texts_to_sequences(test1.question1_modified)\n",
    "test1['tokenizer_2'] = tokenizer.texts_to_sequences(test1.question2_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5741458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['tokenized'] = train1['tokenizer_1'] + train1['tokenizer_2']\n",
    "test1['tokenized'] = test1['tokenizer_1'] + test1['tokenizer_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea75d85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1139, 1139, 2494, 496, 673, 302, 9]\n",
      "[1, 1139, 1139, 2494, 496, 673, 302]\n",
      "[1, 1139, 1139, 2494, 496, 673, 302, 9, 1, 1139, 1139, 2494, 496, 673, 302]\n"
     ]
    }
   ],
   "source": [
    "print (train1['tokenizer_1'][0])\n",
    "print (train1['tokenizer_2'][0])\n",
    "print (train1['tokenized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5cf0a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1934, 767, 112, 378, 1566, 767]\n",
      "[4, 617, 328, 811, 18922, 811, 4184, 175, 1934, 767, 112]\n",
      "[3, 1934, 767, 112, 378, 1566, 767, 4, 617, 328, 811, 18922, 811, 4184, 175, 1934, 767, 112]\n"
     ]
    }
   ],
   "source": [
    "print (test1['tokenizer_1'][0])\n",
    "print (test1['tokenizer_2'][0])\n",
    "print (test1['tokenizer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc9581ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 90580\n"
     ]
    }
   ],
   "source": [
    "max_length = 50\n",
    "max_token = np.max([np.max(train1.tokenized.max()),np.max(test1.tokenizer.max())])\n",
    "print (max_length, max_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7576f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = train1[['is_duplicate']]\n",
    "Xtr = train1[['tokenized']]\n",
    "Xte = test1[['tokenizer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267867e",
   "metadata": {},
   "source": [
    "### Padding & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f03f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "Xtr = pad_sequences(Xtr.tokenized, maxlen = max_length)\n",
    "Xte = pad_sequences(Xte.tokenizer, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a908dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mask for train-test distribution\n",
    "mask = np.random.rand(len(Xtr)) < 0.82\n",
    "Xtr1 = Xtr[mask]\n",
    "Xval = Xtr[~mask]\n",
    "\n",
    "ytr1=ytr[mask]\n",
    "yval=ytr[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463557a",
   "metadata": {},
   "source": [
    "### Modeling Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a24b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, LSTM\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(max_token+1000, 32))\n",
    "model_1.add(Dropout(0.3))\n",
    "\n",
    "model_1.add(LSTM(32))\n",
    "\n",
    "model_1.add(Dropout(0.3))\n",
    "model_1.add(Dense(1, activation = 'sigmoid'))\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e3d818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          2930560   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 32)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,938,913\n",
      "Trainable params: 2,938,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40562719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3873 - accuracy: 0.8232 - val_loss: 0.4651 - val_accuracy: 0.7817\n",
      "Epoch 2/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3839 - accuracy: 0.8249 - val_loss: 0.4649 - val_accuracy: 0.7839\n",
      "Epoch 3/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3811 - accuracy: 0.8263 - val_loss: 0.4681 - val_accuracy: 0.7837\n",
      "Epoch 4/16\n",
      "2594/2594 [==============================] - 53s 20ms/step - loss: 0.3789 - accuracy: 0.8286 - val_loss: 0.4698 - val_accuracy: 0.7866\n",
      "Epoch 5/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3762 - accuracy: 0.8293 - val_loss: 0.4670 - val_accuracy: 0.7835\n",
      "Epoch 6/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3742 - accuracy: 0.8302 - val_loss: 0.4696 - val_accuracy: 0.7839\n",
      "Epoch 7/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3736 - accuracy: 0.8313 - val_loss: 0.4665 - val_accuracy: 0.7803\n",
      "Epoch 8/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3700 - accuracy: 0.8330 - val_loss: 0.4624 - val_accuracy: 0.7847\n",
      "Epoch 9/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3685 - accuracy: 0.8335 - val_loss: 0.4621 - val_accuracy: 0.7854\n",
      "Epoch 10/16\n",
      "2594/2594 [==============================] - 53s 20ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.4742 - val_accuracy: 0.7864\n",
      "Epoch 11/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3656 - accuracy: 0.8368 - val_loss: 0.4666 - val_accuracy: 0.7830\n",
      "Epoch 12/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3639 - accuracy: 0.8367 - val_loss: 0.4748 - val_accuracy: 0.7777\n",
      "Epoch 13/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3634 - accuracy: 0.8370 - val_loss: 0.4621 - val_accuracy: 0.7877\n",
      "Epoch 14/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3607 - accuracy: 0.8389 - val_loss: 0.4640 - val_accuracy: 0.7873\n",
      "Epoch 15/16\n",
      "2594/2594 [==============================] - 51s 20ms/step - loss: 0.3595 - accuracy: 0.8395 - val_loss: 0.4679 - val_accuracy: 0.7855\n",
      "Epoch 16/16\n",
      "2594/2594 [==============================] - 52s 20ms/step - loss: 0.3579 - accuracy: 0.8395 - val_loss: 0.4681 - val_accuracy: 0.7867\n"
     ]
    }
   ],
   "source": [
    "hist = model_1.fit([Xtr1], ytr1, validation_data = ([Xval], yval), epochs = 16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0002505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4582/4582 [==============================] - 128s 28ms/step\n",
      "4582/4582 [==============================] - 134s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model_1.predict(Xte, batch_size=512)\n",
    "preds += model_1.predict(Xte, batch_size=512)\n",
    "preds /= 2\n",
    "\n",
    "results = pd.DataFrame({'test_id':test.test_id, 'is_duplicate':preds.ravel()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dace144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.221046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.327794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.069816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.367610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.221046\n",
       "1        1      0.327794\n",
       "2        2      0.859311\n",
       "3        3      0.069816\n",
       "4        4      0.367610"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
